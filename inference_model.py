# -*- coding: utf-8 -*-
"""inference model

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16BkmbNwgtwTRDDNzAHUBlKhsxiBU0n-H
"""

from google.colab import drive
drive.mount('/content/drive')
# drive.flush_and_unmount()

#@title Find Dataset
import os

DATASET_PATH = "/content/drive/Shareddrives/CMPSC_445-Face_Recognition/images/"

if not os.path.exists(DATASET_PATH):
  print("Please mount your drive using your school email. The dataset is located in the shared drive so we don't have to process the videos to extract the images everytime.")
  extract = 'y' == input("If you want to run the extracting script again, press y: ").lower()
  
  if extract:
    DATSET_PATH = "/content/ml-face-detection/images/"
    # clones git repo to access data and script
    !git clone https://github.com/kendreaditya/ml-face-detection

    # runs script to process videos into images
    !python3 /content/ml-face-detection/image_process.py --dataset_dir "/content/ml-face-detection/data" --output_dir "/content/ml-face-detection/images/"
else:
  print(f"Dataset found at: {DATASET_PATH}")

#@title Imports
import torch
import torch as nn
from torchvision.datasets import ImageFolder
from torchvision import transforms
import torch.optim as optim

import numpy as np
import pandas as pd

from tqdm import tqdm

#@title Define Data Preprocessing Techniques
# Process the data so all the inputs are consistent.

np.random.seed(0)
torch.manual_seed(0)

data_augmentation = [
    # Data Augmentation
    transforms.RandomHorizontalFlip(),
    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),
    transforms.RandomRotation(degrees=10),
    transforms.RandomResizedCrop(size=(256, 256), scale=(0.8, 1.2), ratio=(0.75, 1.33))
]

preprocess = [
    
    # Data Preprocessing
    transforms.CenterCrop(224), # Crops the image to a 224 x 224 image 
    transforms.ToTensor(), # Converts the Image Object to a Tensor object (which is how PyTorch keeps track of its gradients which is used for Backpropagation)
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), # Normalize the images
]

dataset_transforms = {
    'train': transforms.Compose([*data_augmentation, *preprocess]),
    'val': transforms.Compose([transforms.Resize(size=(256, 256)), *preprocess]),
    'test': transforms.Compose([transforms.Resize(size=(256, 256)), *preprocess])
}

#@title Create Dataset & Dataloader
# Create a Dataset Object that takes the image paths (via an path to the folder) and preprocesses them
dataset = ImageFolder(DATASET_PATH)

import math
import random
from collections import defaultdict
from torch.utils.data import Subset, SubsetRandomSampler

def stratified_split(dataset, split_ratios, dataset_transforms=None):
    num_splits = len(split_ratios)
    # Compute class frequencies
    class_freq = defaultdict(int)
    for label in dataset.targets:
        class_freq[label] += 1

    # Compute number of samples per class per split
    num_samples_per_class_per_split = {}
    for label, freq in class_freq.items():
        num_samples_per_class_per_split[label] = [math.ceil(freq * split_ratio) for split_ratio in split_ratios]
    
    import copy
    class_split_freq = copy.deepcopy(num_samples_per_class_per_split)
    
    # Create empty lists for each split
    split_indices = []
    for i in range(num_splits):
        split_indices.append([])

    # Assign indices to each split based on class frequency
    indices = list(range(len(dataset)))
    random.shuffle(indices)
    for idx in indices:
        label = dataset.targets[idx]
        for i in range(num_splits):
            if num_samples_per_class_per_split[label][i] > 0:
                split_indices[i].append(idx)
                num_samples_per_class_per_split[label][i] -= 1

    # Create Subset objects for each split
    splits = []
    for i in range(num_splits):
        split_sampler = SubsetRandomSampler(split_indices[i])
        split_dataset = Subset(dataset, split_indices[i])
        splits.append(split_dataset)
    
    for i in range(len(splits)):
      splits[i] = copy.deepcopy(splits[i])
      splits[i].dataset.transform = dataset_transforms[i]
    return class_split_freq, splits


class_split_freq, [train_dataset, val_dataset, test_dataset] = stratified_split(dataset, [0.7, 0.15, 0.15], dataset_transforms=list(dataset_transforms.values()))

train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)
val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=64, num_workers=2)
test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, num_workers=2)

dataset.classes

# Downloads and initializes the ResNet model from the PyTorch database
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True)
model = nn.nn.Sequential(*list(model.children())[:-1])
model = model.to(device)

"""#Pick TOP 64 correlated features from ResNet Feature Extraction"""

import torch.nn as nn

# Define custom layer
class DimensionalityReduction(nn.Module):
    def __init__(self, df, in_features=512, out_features=64, columns = None):
        super(DimensionalityReduction, self).__init__()
        if columns == None:
          df_top_k = self.find_k_top_corr(df, out_features)
          self.columns = [int(i) for i in list(df_top_k.columns)]        
        else:
          self.columns = columns 
    
    def find_k_top_corr(self, df, number):
      """
        Given a pandas dataframe, and number of columns you want, it returns df with top n correlated columns
    
        Parameters:
        -----------
        df : pandas dataframe
        n  : the number of columns you want as the most correlated columns(features)
    
        Returns:
        --------
        reduced_df : DataFrame
            pandas dataframe with top n most correlated features
        """
      # Calculate the correlation matrix(abs for absolute values, focus on correlation itself)
      corr_matrix = df.corr().abs()
    
      # lets create a mask with size of our corr matrix that filled with ones,  but it will only fill lower trinagle. then convert them as boolean.
      mask = np.tril(np.ones(corr_matrix.shape)).astype(np.bool)
    
      # with using df.mask, we fill the lower triangular matrix to NaN(includes diagonal with 1.0s)
      masked_corr_matrix = corr_matrix.mask(mask)
    
      # using df.unstack() we turn them into a new level of column labels whose inner-most level consists of the pivoted index labels.
      # In summary, we can get new table that each index of feature that has all the correlations of each every other features
      # https://www.w3resource.com/pandas/dataframe/dataframe-unstack.php
      correlations_sorted_table = masked_corr_matrix.unstack(level=1).sort_values(ascending=False)
    
      # now we got every correlation of the matrix in a long line of index, we search top 64 of them without duplicates.
      top_features = []
      for pair in correlations_sorted_table.index:
          # add first pair if length did not reach
          if pair[0] not in top_features and len(top_features) < number:
              top_features.append(pair[0])
          # add second pair if length did not reach
          if pair[1] not in top_features and len(top_features) < number:
              top_features.append(pair[1])
          # break if length reached
          if len(top_features) >= number:
              break
    
      # only pick the columns th"/data" at has top 64 from previous dataframe to our new dataframe
      reduced_df = df[top_features]
    
      return reduced_df

    def forward(self, x):
        # Select only the columns specified in self.columns
        reduced_x = x[:, self.columns].squeeze()

        return reduced_x

k = 64
n_classes = len(dataset.classes)
df = pd.read_csv("/content/drive/Shareddrives/CMPSC_445-Face_Recognition/top-64-ResNet-features.csv")

# Downloads and initializes the ResNet model from the PyTorch database
model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True)

for param in model.parameters():
    param.requires_grad = False

top_k_model = torch.nn.Sequential(*list(model.children())[:-1], DimensionalityReduction(None, in_features=512, out_features=k, columns=list(map(int, df.columns[1:]))), nn.Linear(in_features=64, out_features=n_classes))

checkpoint_path = '/content/drive/Shareddrives/CMPSC_445-Face_Recognition/checkpoints/top-k-model.pt'

# Load the checkpoint file
checkpoint = torch.load(checkpoint_path, map_location=torch.device('cpu'))

# Extract the model state dictionary from the checkpoint
# Create a new instance of your model
# Load the state dictionary into the model
top_k_model.load_state_dict(checkpoint)

import torch
import matplotlib.pyplot as plt
from PIL import Image

def import_image(path, transforms=dataset_transforms['test']):
  image = Image.open(path)
  image = transforms(image)
  return image

def predict(image, model, classes):
    """
    Predict the class of an input image using the provided model.
    
    Args:
        image_path (str): Path to the input image file.
        model: The trained model to use for prediction.
        classes (list): A list of the class names.
        
    Returns:
        None
    """
    
    # Make a prediction using the model
    model.eval()
    with torch.no_grad():
        output = model(image.unsqueeze(0))
    idx = torch.argmax(output)
    predicted_class = classes[idx]
    
    # Display the input image and the predicted class
    plt.imshow(image.permute(1, 2, 0))
    plt.axis('off')
    plt.title(f'Predicted class: {predicted_class}')
    plt.show()

classes = train_loader.dataset.dataset.classes

for images, label in test_loader:
  for i in range(len(images)):
      print(f"Label: {classes[label[i]]}")
      predict(images[i], top_k_model, classes)
  break

image = import_image('/content/drive/Shareddrives/CMPSC_445-Face_Recognition/images/Kenya/Kenya_0.png')
predict(image, top_k_model, classes)