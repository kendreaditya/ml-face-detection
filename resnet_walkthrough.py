# -*- coding: utf-8 -*-
"""ResNet Walkthrough

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1uDe3r2GQHBPB6CZSIfyorC5f0pr6Gz8q
"""

import torch as nn
from torchvision.datasets import ImageFolder
from torchvision import transforms
import torch.optim as optim

# Process the data so all the inputs are consistent.
preprocess = transforms.Compose([
    transforms.Resize(256), # Resizes the image so that the smallest size is 256
    transforms.CenterCrop(224), # Crops the image to a 224 x 224 image 
    transforms.ToTensor(), # Converts the Image Object to a Tensor object (which is how PyTorch keeps track of its gradients which is used for Backpropagation)
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), # Normalize the images
])

# Create a Dataset Object that takes the image paths (via an path to the folder) and preprocesses them
dataset = ImageFolder("./dataset/", preprocess)

# The strcture of the Image Folder Looks like this
"""
root/dog/xxx.png
root/dog/xxy.png
root/dog/[...]/xxz.png

root/cat/123.png
root/cat/nsdf3.png
root/cat/[...]/asd932_.png
"""

# Creats a DataLoader, which takes in the Dataset object and gets it ready for training
#     This is done by making the dataset into batches and shuffles them
#     So on each iteration the (for images in dataloader) n number of images are give (in this case 5)
trainloader = nn.torch.utils.data.DataLoader(dataset, batch_size=5,
                                          shuffle=True, num_workers=2)

# Downloads and initializes the ResNet model from the PyTorch database
model = nn.torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True)

# Loss and Optimizer
criterion = nn.CrossEntropyLoss() # Same as Log Loss
optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9) # Backpropagation (We haven't learn about this yet, but its how backpropagation is done)

